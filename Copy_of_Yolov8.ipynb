{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "video_path = \"/content/Himanshu_New_Dataset.mp4\"  # your dataset video\n",
        "output_folder = \"dataset/images\"\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "frame_id = 0\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    if frame_id % 5 == 0:  # take 1 frame every 5 frames\n",
        "        cv2.imwrite(f\"{output_folder}/frame_{frame_id}.jpg\", frame)\n",
        "    frame_id += 1\n",
        "\n",
        "cap.release()\n"
      ],
      "metadata": {
        "id": "oe18UizarD4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "# Zip the dataset folder\n",
        "shutil.make_archive(\"/content/dataset\", 'zip', \"/content/dataset\")\n",
        "\n",
        "# Download the dataset zip (only in Google Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"/content/dataset.zip\")\n",
        "except:\n",
        "    print(\"Not running in Colab. Zip file saved at /content/dataset.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TCZkismMrD7c",
        "outputId": "a6e90544-a41d-4d48-8fcf-8128fed9c8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f93fb48c-956b-4b0e-ad76-7514dcdc68e4\", \"dataset.zip\", 10423914)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T91UEdRwrD-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another Approach"
      ],
      "metadata": {
        "id": "0aB7Mexu-X85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-python mediapipe ultralytics scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UelTohperEBY",
        "outputId": "8dae2778-74bf-48a9-cab3-b034a41fa935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.193-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy<2.3.0,>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python) (2.0.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "INFO: pip is looking at multiple versions of mediapipe to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.20-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading mediapipe-0.10.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading mediapipe-0.10.15-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "  Downloading mediapipe-0.10.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.12/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.3)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading mediapipe-0.10.14-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.193-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.2-py3-none-any.whl (32 kB)\n",
            "Downloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: protobuf, sounddevice, ultralytics-thop, mediapipe, ultralytics\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mediapipe-0.10.14 protobuf-4.25.8 sounddevice-0.5.2 ultralytics-8.3.193 ultralytics-thop-2.0.17\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "354c832c27734db9a8874ce66e710f1a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q95y1Fz2rEH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z4SXenKKrEKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Labelled Images in Alert and Drowsy in Yolo_dataset folder"
      ],
      "metadata": {
        "id": "rvCc8HgqEire"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import mediapipe as mp\n",
        "import os\n",
        "\n",
        "# ===============================\n",
        "# STEP 1: Setup MediaPipe & EAR function\n",
        "# ===============================\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "# Left & right eye landmark indices (MediaPipe standard)\n",
        "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
        "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
        "\n",
        "def euclidean_dist(pt1, pt2):\n",
        "    return ((pt1[0] - pt2[0])**2 + (pt1[1] - pt2[1])**2) ** 0.5\n",
        "\n",
        "def compute_EAR(landmarks, eye_points, w, h):\n",
        "    # Get coordinates\n",
        "    p1 = (landmarks[eye_points[0]].x * w, landmarks[eye_points[0]].y * h)\n",
        "    p2 = (landmarks[eye_points[1]].x * w, landmarks[eye_points[1]].y * h)\n",
        "    p3 = (landmarks[eye_points[2]].x * w, landmarks[eye_points[2]].y * h)\n",
        "    p4 = (landmarks[eye_points[3]].x * w, landmarks[eye_points[3]].y * h)\n",
        "    p5 = (landmarks[eye_points[4]].x * w, landmarks[eye_points[4]].y * h)\n",
        "    p6 = (landmarks[eye_points[5]].x * w, landmarks[eye_points[5]].y * h)\n",
        "\n",
        "    # EAR formula\n",
        "    ear = (euclidean_dist(p2,p6) + euclidean_dist(p3,p5)) / (2.0 * euclidean_dist(p1,p4))\n",
        "    return ear\n",
        "\n",
        "# ===============================\n",
        "# STEP 2: Create folders\n",
        "# ===============================\n",
        "output_dir = \"yolo_dataset\"\n",
        "alert_dir = os.path.join(output_dir, \"Alert\")\n",
        "drowsy_dir = os.path.join(output_dir, \"Drowsy\")\n",
        "os.makedirs(alert_dir, exist_ok=True)\n",
        "os.makedirs(drowsy_dir, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# STEP 3: Process video\n",
        "# ===============================\n",
        "cap = cv2.VideoCapture(\"/content/Himanshu_New_Dataset.mp4\")  # change to your video file\n",
        "frame_count = 0\n",
        "EAR_THRESHOLD = 0.25  # tweak if needed\n",
        "\n",
        "with mp_face_mesh.FaceMesh(static_image_mode=False, max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        h, w, _ = frame.shape\n",
        "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = face_mesh.process(rgb_frame)\n",
        "\n",
        "        if results.multi_face_landmarks:\n",
        "            for landmarks in results.multi_face_landmarks:\n",
        "                leftEAR = compute_EAR(landmarks.landmark, LEFT_EYE, w, h)\n",
        "                rightEAR = compute_EAR(landmarks.landmark, RIGHT_EYE, w, h)\n",
        "                EAR = (leftEAR + rightEAR) / 2.0\n",
        "\n",
        "                # Classification (Alert or Drowsy)\n",
        "                if EAR < EAR_THRESHOLD:\n",
        "                    label = \"Drowsy\"\n",
        "                    save_path = os.path.join(drowsy_dir, f\"drowsy_{frame_count}.jpg\")\n",
        "                else:\n",
        "                    label = \"Alert\"\n",
        "                    save_path = os.path.join(alert_dir, f\"alert_{frame_count}.jpg\")\n",
        "\n",
        "                # Save frame\n",
        "                cv2.imwrite(save_path, frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "print(\"✅ Frames saved into dataset/Alert and dataset/Drowsy\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SmDVkswrENq",
        "outputId": "fd6f0a28-85f0-475c-b26e-5015536a1abe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
            "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Frames saved into dataset/Alert and dataset/Drowsy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U7ndIbVeFGbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inGX8pS4FGXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Rr8BPZRBFGU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wvHf2MjtFGC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labels"
      ],
      "metadata": {
        "id": "J82uMEI2BVDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "from glob import glob\n",
        "\n",
        "# ===============================\n",
        "# Config\n",
        "# ===============================\n",
        "dataset_dir = \"/content/yolo_dataset\"  # folder with Alert/ Drowsy\n",
        "output_label_dir = \"dataset_labels\"\n",
        "os.makedirs(output_label_dir, exist_ok=True)\n",
        "\n",
        "# classes mapping\n",
        "classes = {\"Alert\": 0, \"Drowsy\": 1}\n",
        "\n",
        "# Eye landmark indices (for bounding box)\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "# ===============================\n",
        "# Functions\n",
        "# ===============================\n",
        "def get_face_bbox(landmarks, img_w, img_h, margin=0.2):\n",
        "    xs = [lm.x * img_w for lm in landmarks]\n",
        "    ys = [lm.y * img_h for lm in landmarks]\n",
        "    x1, y1 = max(0, min(xs)), max(0, min(ys))\n",
        "    x2, y2 = min(img_w - 1, max(xs)), min(img_h - 1, max(ys))\n",
        "\n",
        "    # expand bbox by margin\n",
        "    bw, bh = x2 - x1, y2 - y1\n",
        "    x1 = max(0, x1 - bw * margin)\n",
        "    y1 = max(0, y1 - bh * margin)\n",
        "    x2 = min(img_w - 1, x2 + bw * margin)\n",
        "    y2 = min(img_h - 1, y2 + bh * margin)\n",
        "\n",
        "    return int(x1), int(y1), int(x2), int(y2)\n",
        "\n",
        "def save_yolo_label(image_path, label_path, class_id, bbox):\n",
        "    x1, y1, x2, y2 = bbox\n",
        "    img = cv2.imread(image_path)\n",
        "    h, w, _ = img.shape\n",
        "\n",
        "    x_center = (x1 + x2)/2 / w\n",
        "    y_center = (y1 + y2)/2 / h\n",
        "    bw = (x2 - x1)/w\n",
        "    bh = (y2 - y1)/h\n",
        "\n",
        "    line = f\"{class_id} {x_center:.6f} {y_center:.6f} {bw:.6f} {bh:.6f}\\n\"\n",
        "    with open(label_path, \"w\") as f:\n",
        "        f.write(line)\n",
        "\n",
        "# ===============================\n",
        "# Process all images\n",
        "# ===============================\n",
        "with mp_face_mesh.FaceMesh(static_image_mode=True, max_num_faces=1, refine_landmarks=True) as face_mesh:\n",
        "    for cls_name in [\"Alert\", \"Drowsy\"]:\n",
        "        cls_dir = os.path.join(dataset_dir, cls_name)\n",
        "        images = glob(os.path.join(cls_dir, \"*.jpg\"))\n",
        "        for img_path in images:\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                continue\n",
        "            h, w, _ = img.shape\n",
        "            rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            results = face_mesh.process(rgb_img)\n",
        "            if results.multi_face_landmarks:\n",
        "                lms = results.multi_face_landmarks[0].landmark\n",
        "                bbox = get_face_bbox(lms, w, h)\n",
        "                # save label\n",
        "                label_filename = os.path.basename(img_path).replace(\".jpg\", \".txt\")\n",
        "                label_path = os.path.join(output_label_dir, label_filename)\n",
        "                save_yolo_label(img_path, label_path, classes[cls_name], bbox)\n",
        "\n",
        "print(\"✅ YOLO annotation files created in:\", output_label_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oZ1ZLgzrEU6",
        "outputId": "a64d60bc-8337-4942-bed7-76e5c2021fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ YOLO annotation files created in: dataset_labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# ===============================\n",
        "# Config\n",
        "# ===============================\n",
        "images_dir = \"yolo_dataset\"            # Your images: dataset/Alert & dataset/Drowsy\n",
        "labels_dir = \"dataset_labels\"     # Your YOLO txt labels\n",
        "output_dir = \"yolo_final_output\"       # Final folder for YOLOv8\n",
        "random_seed = 42\n",
        "val_ratio = 0.1\n",
        "test_ratio = 0.1\n",
        "\n",
        "classes = [\"Alert\", \"Drowsy\"]\n",
        "\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ===============================\n",
        "# Gather all images and labels\n",
        "# ===============================\n",
        "all_images = []\n",
        "for cls in classes:\n",
        "    cls_dir = os.path.join(images_dir, cls)\n",
        "    imgs = glob.glob(os.path.join(cls_dir, \"*.jpg\"))\n",
        "    for img_path in imgs:\n",
        "        label_path = os.path.join(labels_dir, os.path.basename(img_path).replace(\".jpg\", \".txt\"))\n",
        "        if os.path.exists(label_path):\n",
        "            all_images.append((img_path, label_path))\n",
        "\n",
        "print(f\"Total labeled images found: {len(all_images)}\")\n",
        "\n",
        "# ===============================\n",
        "# Shuffle and split\n",
        "# ===============================\n",
        "random.seed(random_seed)\n",
        "random.shuffle(all_images)\n",
        "\n",
        "n_total = len(all_images)\n",
        "n_val = int(n_total * val_ratio)\n",
        "n_test = int(n_total * test_ratio)\n",
        "n_train = n_total - n_val - n_test\n",
        "\n",
        "train_set = all_images[:n_train]\n",
        "val_set   = all_images[n_train:n_train+n_val]\n",
        "test_set  = all_images[n_train+n_val:]\n",
        "\n",
        "splits = {\"train\": train_set, \"val\": val_set, \"test\": test_set}\n",
        "\n",
        "# ===============================\n",
        "# Copy images and labels to YOLO structure\n",
        "# ===============================\n",
        "for split, dataset in splits.items():\n",
        "    img_out = os.path.join(output_dir, \"images\", split)\n",
        "    lbl_out = os.path.join(output_dir, \"labels\", split)\n",
        "    os.makedirs(img_out, exist_ok=True)\n",
        "    os.makedirs(lbl_out, exist_ok=True)\n",
        "\n",
        "    for img_path, lbl_path in dataset:\n",
        "        shutil.copy2(img_path, os.path.join(img_out, os.path.basename(img_path)))\n",
        "        shutil.copy2(lbl_path, os.path.join(lbl_out, os.path.basename(lbl_path)))\n",
        "\n",
        "# ===============================\n",
        "# Create data.yaml\n",
        "# ===============================\n",
        "yaml_path = os.path.join(output_dir, \"data.yaml\")\n",
        "with open(yaml_path, \"w\") as f:\n",
        "    f.write(f\"train: {os.path.abspath(os.path.join(output_dir,'images','train'))}\\n\")\n",
        "    f.write(f\"val: {os.path.abspath(os.path.join(output_dir,'images','val'))}\\n\")\n",
        "    f.write(f\"test: {os.path.abspath(os.path.join(output_dir,'images','test'))}\\n\\n\")\n",
        "    f.write(f\"nc: {len(classes)}\\n\")\n",
        "    f.write(f\"names: {classes}\\n\")\n",
        "\n",
        "print(f\"✅ YOLOv8 dataset ready! data.yaml created at: {yaml_path}\")\n"
      ],
      "metadata": {
        "id": "Ob3uAELfkKJ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee9249f2-47bf-4af2-ed9b-b272f6e9a72a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total labeled images found: 956\n",
            "✅ YOLOv8 dataset ready! data.yaml created at: yolo_final_output/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "!yolo detect train model=yolov8n.pt data=yolo_final_output/data.yaml epochs=10 imgsz=640\n"
      ],
      "metadata": {
        "id": "wrIr5XqvkKMt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a3b5cc-9580-4d35-b58c-e1b8c578d662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% ━━━━━━━━━━━━ 6.2MB 121.1MB/s 0.1s\n",
            "Ultralytics 8.3.193 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=yolo_final_output/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/detect/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 36.5MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,238 parameters, 3,011,222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% ━━━━━━━━━━━━ 5.4MB 134.7MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1454.7±454.8 MB/s, size: 45.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_final_output/labels/train... 766 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 766/766 2.4Kit/s 0.3s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_final_output/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1020.8±569.7 MB/s, size: 45.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_final_output/labels/val... 95 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 95/95 1.9Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_final_output/labels/val.cache\n",
            "Plotting labels to /content/runs/detect/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/10      2.08G     0.7642      2.394      1.526         14        640: 100% ━━━━━━━━━━━━ 48/48 3.0it/s 16.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 1.7it/s 1.8s\n",
            "                   all         95         95      0.846      0.857      0.935      0.846\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/10      2.56G     0.4056      1.329      1.043         14        640: 100% ━━━━━━━━━━━━ 48/48 3.7it/s 12.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.0it/s 1.0s\n",
            "                   all         95         95      0.951      0.903      0.981       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/10      2.58G     0.3867      1.061      1.024         14        640: 100% ━━━━━━━━━━━━ 48/48 3.9it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.1it/s 1.0s\n",
            "                   all         95         95      0.942      0.967      0.994      0.926\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/10       2.6G     0.3521     0.9095     0.9853         14        640: 100% ━━━━━━━━━━━━ 48/48 3.9it/s 12.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 3.0it/s 1.0s\n",
            "                   all         95         95      0.872      0.952      0.936      0.867\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/10      2.62G     0.3087     0.7316     0.9484         14        640: 100% ━━━━━━━━━━━━ 48/48 3.9it/s 12.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.1it/s 1.4s\n",
            "                   all         95         95      0.843      0.851      0.896      0.865\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/10      2.63G      0.272       0.65     0.9195         14        640: 100% ━━━━━━━━━━━━ 48/48 3.8it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 1.6it/s 1.9s\n",
            "                   all         95         95      0.895      0.909      0.958      0.928\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/10      2.65G     0.2494     0.5473     0.8896         14        640: 100% ━━━━━━━━━━━━ 48/48 4.1it/s 11.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 1.8it/s 1.6s\n",
            "                   all         95         95      0.891      0.959      0.975      0.973\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/10      2.67G     0.2329     0.4957     0.8895         14        640: 100% ━━━━━━━━━━━━ 48/48 3.9it/s 12.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.4it/s 1.2s\n",
            "                   all         95         95      0.949      0.991       0.99      0.979\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/10      2.68G     0.2072     0.4318     0.8798         14        640: 100% ━━━━━━━━━━━━ 48/48 3.8it/s 12.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.9it/s 1.0s\n",
            "                   all         95         95      0.975      0.993      0.994      0.993\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/10       2.7G     0.1828     0.4008     0.8568         14        640: 100% ━━━━━━━━━━━━ 48/48 3.9it/s 12.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 2.8it/s 1.1s\n",
            "                   all         95         95      0.969          1      0.993      0.992\n",
            "\n",
            "10 epochs completed in 0.040 hours.\n",
            "Optimizer stripped from /content/runs/detect/train/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs/detect/train/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs/detect/train/weights/best.pt...\n",
            "Ultralytics 8.3.193 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,006,038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 1.9it/s 1.6s\n",
            "                   all         95         95      0.975      0.993      0.994      0.993\n",
            "                 Alert         22         22       0.95          1      0.993      0.993\n",
            "                Drowsy         73         73          1      0.986      0.995      0.993\n",
            "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/train\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"GPU available:\", torch.cuda.is_available())\n",
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "dvY2xpA3kKPl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdcf5f93-9dd5-4586-c660-640af7bf26ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: False\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dt3n_jZikKSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7UdtQGU9kKV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A_HKQOKBkKY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FbNGEACDkKcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nV5rI6tkkKfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UCaC6dd2kKiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uTPaAbQwkKlv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PyOd_jWXkKo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mKZajNHLkKrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OHFCBgoZkKu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9IeJgUdDkKyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RYiYev0ckK02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Tp3YTuOkK39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iS-rstOvkK6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zdVdPK4ZkK9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bo3JNqF5kLBK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}